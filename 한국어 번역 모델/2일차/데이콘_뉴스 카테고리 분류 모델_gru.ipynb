{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train_data.csv')\n",
    "test = pd.read_csv('data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>topic_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>인천→핀란드 항공기 결항…휴가철 여행객 분통</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>시진핑 트럼프에 중미 무역협상 조속 타결 희망</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                             title  topic_idx\n",
       "0      0          인천→핀란드 항공기 결항…휴가철 여행객 분통          4\n",
       "1      1    실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화          4\n",
       "2      2    이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것          4\n",
       "3      3  NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합          4\n",
       "4      4         시진핑 트럼프에 중미 무역협상 조속 타결 희망          4"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('인천', 'Noun'),\n",
       " ('→', 'Foreign'),\n",
       " ('핀란드', 'Noun'),\n",
       " ('항공기', 'Noun'),\n",
       " ('결항', 'Noun'),\n",
       " ('…', 'Punctuation'),\n",
       " ('휴가', 'Noun'),\n",
       " ('철', 'Noun'),\n",
       " ('여행객', 'Noun'),\n",
       " ('분통', 'Noun')]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pos(train['title'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchtext.legacy import data \n",
    "from konlpy.tag import Okt\n",
    "\n",
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(title):\n",
    "    return len(title)\n",
    "\n",
    "train['title_len'] = train['title'].apply(get_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train['title_len'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='title_len', ylabel='Count'>"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.median(train['title_len'].to_list())\n",
    "np.max(train['title_len'].to_list())\n",
    "\n",
    "sns.histplot(train['title_len'],bins = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필드 정의\n",
    "INDEX = data.Field(sequential = False,\n",
    "                use_vocab = False) # 실제 사용은 하지 않을 예정\n",
    "\n",
    "TITLE = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=tokenizer.morphs, # 토크나이저로는 Okt 사용.\n",
    "                  lower=True,\n",
    "                  batch_first=True,\n",
    "                  fix_length=44)\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   is_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "for i,(trn_idx,val_idx) in enumerate(skf.split(train['title'],train['topic_idx'])):\n",
    "    trn = train.iloc[trn_idx]\n",
    "    val = train.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn.to_csv('data/trn.csv',index = False)\n",
    "val.to_csv('data/val.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['topic_idx'] = 0\n",
    "test.to_csv('data/test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import TabularDataset\n",
    "\n",
    "train_data, validation_data,test_data =TabularDataset.splits(\n",
    "     path='data/', train='trn.csv',validation= 'val.csv', test='test.csv', format='csv',\n",
    "        fields=[('index', INDEX), ('title', TITLE), ('topix_idx', LABEL)], skip_header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 36524\n",
      "검증 샘플의 개수 : 9130\n",
      "테스트 샘플의 개수 : 9131\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
    "print('검증 샘플의 개수 : {}'.format(len(validation_data)))\n",
    "print('테스트 샘플의 개수 : {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE.build_vocab(train_data, min_freq = 2, max_size = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 18587\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합의 크기 : {}'.format(len(TITLE.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(67)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(test_loader))\n",
    "\n",
    "\n",
    "torch.sum(torch.where(batch.title==0,True,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로더 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Iterator(dataset = train_data, batch_size = batch_size)\n",
    "val_loader = Iterator(dataset = validation_data, batch_size = batch_size)\n",
    "test_loader = Iterator(dataset = test_data, batch_size = batch_size,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치 수 : 286\n",
      "검증 데이터의 미니 배치 수 : 72\n",
      "테스트 데이터의 미니 배치 수 : 72\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_loader)))\n",
    "print('검증 데이터의 미니 배치 수 : {}'.format(len(val_loader)))\n",
    "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
    "                          num_layers=self.n_layers,\n",
    "                          batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        h_0 = self._init_state(batch_size=x.size(0)) # 첫번째 히든 스테이트를 0벡터로 초기화\n",
    "        x, _ = self.gru(x, h_0)  # GRU의 리턴값은 (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\n",
    "        h_t = x[:,-1,:] # 모든 문장을 거쳐서 나온 가장 마지막에 나온 단어(평점)의 값\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)  # (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\n",
    "        return logit\n",
    "\n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 18587\n",
      "클래스의 개수 : 7\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(TITLE.vocab) \n",
    "n_classes = 7\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('클래스의 개수 : {}'.format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GRU(1, 8, vocab_size , 128, n_classes, 0.2).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_iter):\n",
    "        x, y = batch.title.to(DEVICE), batch.topix_idx.to(DEVICE)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logit = model(x)\n",
    "        y= torch.tensor(y,dtype = torch.long,device =DEVICE)\n",
    "\n",
    "        loss = F.cross_entropy(logit,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter,test_iter):\n",
    "    \"\"\"evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    batch_cor, total_loss = 0, 0\n",
    "    \n",
    "    for batch in val_iter:\n",
    "        x, y = batch.title.to(DEVICE), batch.topix_idx.to(DEVICE)\n",
    "        y= torch.tensor(y,dtype = torch.long,device =DEVICE)\n",
    "        logit = model(x)\n",
    "        \n",
    "        loss = F.cross_entropy(logit, y)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        batch_cor += (logit.max(1)[1] == y.data).sum() \n",
    "        \n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size \n",
    "    avg_accuracy = 100.0 * batch_cor / size\n",
    "    \n",
    "    \n",
    "    preds = []\n",
    "    pred = []\n",
    "    for batch in test_iter:\n",
    "        x, y = batch.title.to(DEVICE), batch.topix_idx.to(DEVICE)\n",
    "        \n",
    "        logit = model(x)\n",
    "        pred=torch.argmax(logit,axis= 1).tolist()\n",
    "        preds.extend(pred)\n",
    "    \n",
    "    return avg_loss, avg_accuracy,preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] val loss : 0.00788 | val accuracy : 73.15\n",
      "[Epoch: 2] val loss : 0.00803 | val accuracy : 73.17\n",
      "[Epoch: 3] val loss : 0.00829 | val accuracy : 73.27\n",
      "[Epoch: 4] val loss : 0.00844 | val accuracy : 73.07\n",
      "[Epoch: 5] val loss : 0.00852 | val accuracy : 73.08\n",
      "[Epoch: 6] val loss : 0.00870 | val accuracy : 72.87\n",
      "[Epoch: 7] val loss : 0.00896 | val accuracy : 72.65\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-436-409643d55e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-426-260aaa946c30>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_iter)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bdg/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bdg/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "best_model = []\n",
    "EPOCHS = 10\n",
    "for e in range(1, EPOCHS + 1 ):\n",
    "    train(model, optimizer, train_loader)\n",
    "    val_loss, val_accuracy,preds = evaluate(model, val_loader,test_loader)\n",
    "\n",
    "    print(\"[Epoch: %d] val loss : %5.5f | val accuracy : %5.2f\" % (e, val_loss, val_accuracy))\n",
    "\n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "        submission.topic_idx = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bset model로 예측.\n",
    "\n",
    "def predict(model, test_iter):\n",
    "    \"\"\"evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    pred = []\n",
    "    for batch in test_iter:\n",
    "        x, y = batch.title.to(DEVICE), batch.topix_idx.to(DEVICE)\n",
    "        \n",
    "        logit = model(x)\n",
    "        pred=torch.argmax(logit,axis= 1).tolist()\n",
    "        preds.extend(pred)\n",
    "    return preds \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9131"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict(best_model,test_loader)\n",
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission.topic_idx = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('gru.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1504\n",
       "0    1420\n",
       "6    1385\n",
       "1    1385\n",
       "5    1249\n",
       "2    1184\n",
       "3    1004\n",
       "Name: topic_idx, dtype: int64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.topic_idx.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
